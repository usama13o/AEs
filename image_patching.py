# -*- coding: utf-8 -*-
"""image_patching

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/104JWAy1GBlD0MW2n_Hwwt-n8E2-uR5iF
"""

import pickle
import PIL.Image
import tifffile
import numpy as np

import argparse

# for i in *.tif; do python /home/uz1/projects/AEs/image_patching.py --img $i --save_pkl; done
# for i in *.jpg; do python /home/uz1/projects/AEs/image_patching.py --img "$i" --save_dir /home/uz1/data/geo/slices/64 ; done
# 38k patches from 20 tifs

parser = argparse.ArgumentParser(description='Image patching for Geology data')
parser.add_argument('--img', help="Img to slice")
parser.add_argument('--save_dir', help="Img to slice")
parser.add_argument('--save_pkl', help="save as pickle files",action="store_true")
parser.add_argument('--stride', help="save as pickle files",type=int)
args= parser.parse_args()

SAVE_AS_PICKLE = True if args.save_pkl ==True else False
print(f"Save as Pickle --> {SAVE_AS_PICKLE}")
IMG_TO_SLICE = args.img if hasattr(args,'img') else "/home/uz1/data/geo/9-Bands_Composite_Tiff (1).tif" 

print(f"Image to slice is : {IMG_TO_SLICE}")
if '.tif' in IMG_TO_SLICE:
    image= tifffile.imread(IMG_TO_SLICE).transpose(1,2,0)
elif '.pkl' in IMG_TO_SLICE:
    with open(IMG_TO_SLICE, "rb") as f_in:
        image = pickle.load(f_in)
else:
    image = np.array(PIL.Image.open(IMG_TO_SLICE))
print(image.shape)


img = image.shape
stride = (args.stride,args.stride)
output_size=(64,64)
fn = IMG_TO_SLICE.split('/')[-1][:-4]
#where to save ?
SAVE_DIR = f"/home/uz1/data/geo/slices_raw/" + str(output_size[0])+ f'/{fn}_raw_unclipped' if args.save_dir == '' else args.save_dir + f"/{fn}"
print(f"saveing to : {SAVE_DIR}")

y=img[1]
x=img[0]
a = output_size[0]
b = output_size[1]
s_x = stride[0]
s_y = stride[1]

num_images = (((y - b) // s_y)+1) * (((x - a) // s_x) + 1)
print("Number of Images to produce: ", num_images)

import numpy as np
import matplotlib.pyplot as plt
import os
import tifffile

class ImageSlicer(object):
    
    def __init__(self, source, size, strides=[None, None], BATCH = False, PADDING=False):
        self.source = source
        self.size = size
        self.strides = strides
        self.BATCH = BATCH
        self.PADDING = PADDING
        
    def __read_images(self):
        Images = []
        image_names = sorted(os.listdir(self.source))
        for im in image_names:
            image = plt.imread(os.path.join(dir_path,im))
            Images.append(image)
        return Images

    def __offset_op(self, input_length, output_length, stride):
        offset = (input_length) - (stride*((input_length - output_length)//stride)+output_length)
        return offset
    
    def __padding_op(self, Image):
        if self.offset_x > 0:
            padding_x = self.strides[0] - self.offset_x
        else:
            padding_x = 0
        if self.offset_y > 0:
            padding_y = self.strides[1] - self.offset_y
        else:
            padding_y = 0
        Padded_Image = np.zeros(shape=(Image.shape[0]+padding_x, Image.shape[1]+padding_y, Image.shape[2]),dtype=Image.dtype)
        Padded_Image[padding_x//2:(padding_x//2)+(Image.shape[0]),padding_y//2:(padding_y//2)+Image.shape[1],:] = Image    
        return Padded_Image

    def __convolution_op(self, Image):
        start_x = 0
        start_y = 0
        n_rows = Image.shape[0]//self.strides[0] + 1
        n_columns = Image.shape[1]//self.strides[1] + 1
        small_images = []
        for i in range(n_rows-1):
            for j in range(n_columns-1):
                new_start_x = start_x+i*self.strides[0]
                new_start_y= start_y+j*self.strides[1]
                small_images.append(Image[new_start_x:new_start_x+self.size[0],new_start_y:new_start_y+self.size[1],:])
        return small_images

    def transform(self):
        
        if not(os.path.exists(self.source)):
            raise Exception("Path does not exist!")
            
        else:
            if self.source and not(self.BATCH):
            
                if '.tif' in self.source or 'tif' in self.source:
                  Image= tifffile.imread(self.source).transpose(1,2,0)
                  Images=[Image]
                elif '.pickle' in self.source:
                    with open(self.source, "rb") as f_in:
                        Images = pickle.load(f_in)
                    Images=[Images]    
                else:
                  Image = plt.imread(self.source)
                  Images = [Image]
            else: 
                Images = self.__read_images()

            im_size = Images[0].shape
            num_images = len(Images)
            transformed_images = dict()
            Images = np.array(Images)
            
            if self.PADDING:
                
                padded_images = []

                if self.strides[0]==None and self.strides[1]==None:
                    self.strides[0] = self.size[0]
                    self.strides[1] = self.size[1]
                    self.offset_x = Images.shape[1]%self.size[0]
                    self.offset_y = Images.shape[2]%self.size[1]
                    padded_images = list(map(self.__padding_op, Images))
                                         
                elif self.strides[0]==None and self.strides[1]!=None:   
                    self.strides[0] = self.size[0]
                    self.offset_x = Images.shape[1]%self.size[0]
                    if self.strides[1] <= Images.shape[2]:
                        self.offset_y = self.__offset_op(Images.shape[2], self.size[1], self.strides[1])
                    else:
                        raise Exception("stride_y must be between {0} and {1}".format(1,Images.shape[2]))
                    padded_images = list(map(self.__padding_op, Images))

                elif self.strides[0]!=None and self.strides[1]==None:   
                    self.strides[1] = self.size[1]
                    self.offset_y = Images.shape[2]%self.size[1]
                    if self.strides[0] <=Images.shape[1]:
                        self.offset_x = self.__offset_op(Images.shape[1], self.size[0], self.strides[0])
                    else:
                        raise Exception("stride_x must be between {0} and {1}".format(1,Images.shape[1]))
                    padded_images = list(map(self.__padding_op, Images))
                                         
                else:
                    if self.strides[0] > Images.shape[1]:
                        raise Exception("stride_x must be between {0} and {1}".format(1,Images.shape[1]))
                    
                    elif self.strides[1] > Images.shape[2]:
                        raise Exception("stride_y must be between {0} and {1}".format(1,Images.shape[2]))
                        
                    else:
                        self.offset_x = self.__offset_op(Images.shape[1], self.size[0], self.strides[0])
                        self.offset_y = self.__offset_op(Images.shape[2], self.size[1], self.strides[1])
                        padded_images = list(map(self.__padding_op, Images))

                for i, Image in enumerate(padded_images):
                    transformed_images[str(i)] = self.__convolution_op(Image)

            else:
                if self.strides[0]==None and self.strides[1]==None:
                    self.strides[0] = self.size[0]
                    self.strides[1] = self.size[1]

                elif self.strides[0]==None and self.strides[1]!=None:
                    if self.strides[1] > Images.shape[2]:
                        raise Exception("stride_y must be between {0} and {1}".format(1,Images.shape[2]))                 
                    self.strides[0] = self.size[0]

                elif self.strides[0]!=None and self.strides[1]==None:
                    if self.strides[0] > Images.shape[1]:
                        raise Exception("stride_x must be between {0} and {1}".format(1,Images.shape[1]))              
                    self.strides[1] = self.size[1]
                else:
                    if self.strides[0] > Images.shape[1]:
                        raise Exception("stride_x must be between {0} and {1}".format(1,Images.shape[1]))                    
                    elif self.strides[1] > Images.shape[2]:
                        raise Exception("stride_y must be between {0} and {1}".format(1,Images.shape[2]))
                                         
                for i, Image in enumerate(Images):
                    transformed_images[str(i)] = self.__convolution_op(Image)

            return transformed_images
        
    def save_images(self,transformed, save_dir,save_as_pickle=True):
        if not(os.path.exists(save_dir)):
            raise Exception("Path does not exist!")
        else:
            for key, val in transformed.items():
                path = os.path.join(save_dir, key)
                os.mkdir(path)
                for i, j in enumerate(val):
                    if not save_as_pickle:
                        plt.imsave(os.path.join(path, str(i+1)+'.png'), j)
                    else:
                        with open(os.path.join(path, str(i+1)+".pickle"), "wb") as f_out:
                            pickle.dump(j, f_out)



# from ImageSlicer import ImageSlicer
import os
try:
  os.makedirs(SAVE_DIR)
except Exception:
  print('File exists ') 
  
  
slicer = ImageSlicer(IMG_TO_SLICE, output_size,stride) #Provide image path and slice size you desire
transformed_image = slicer.transform()
print("Number of all slices ",len(transformed_image['0']))

while(len(transformed_image['0']) !=num_images):
  for idx,im in enumerate(transformed_image['0']):
    if im.shape[0]!= a or im.shape[1] != b:
    #   print("Removing idx: ",idx)
      transformed_image['0'].pop(idx)
    
print("Slices to save: ",len(transformed_image['0']))

slicer.save_images(transformed_image,SAVE_DIR,save_as_pickle=SAVE_AS_PICKLE) #Provide the directory where you want to save the sliced images

print("** DONE! **")